{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "In order to load data from rasters into python, we need to use the `rasterio` module. Below is an example of how to open and visualize a file using rasterio.\n",
    "\n",
    "### Finding files\n",
    "\n",
    "Before we can load files, we need to know where they are at. In this case, there is some NAIP data that has aleady been sampled stored in `./data` with the following directory structure:\n",
    "\n",
    "```\n",
    "| data/\n",
    "|| NAIP_PATCH_ID/ \n",
    "||| input/\n",
    "|||| 00000.tif (sample from corresponding patch)\n",
    "|||| 00001.tif\n",
    "|||| 00002.tif\n",
    "|||| ...\n",
    "||| target/\n",
    "|||| 00000.tif (sampl from corresponding patch's ground truth data)\n",
    "|||| 00001.tif\n",
    "|||| 00002.tif\n",
    "|||| ...\n",
    "```\n",
    "\n",
    "Knowing this, we can write a function that aggregates the NAIP data and their corresponding ground truth labels into a list of 2-tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2464 files\n",
      "('./data/m_3607632_ne_18_1/input/00397.tif', './data/m_3607632_ne_18_1/target/00397.tif')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def get_list_of_files(data_path: str='./data') -> list[tuple[str, str]]:\n",
    "    '''Returns a list of tuples of the form (path_to_input_sample, path_to_label)\n",
    "    \n",
    "    Parameters:\n",
    "    data_path (str): path to the root of the data directory\n",
    "    \n",
    "    Returns:\n",
    "    list[tuple[str, str]]: List of file paths with corresponding ground truth labels\n",
    "    '''\n",
    "    \n",
    "    # get list of patch ids. list comprehension pretty much says \"look at the \n",
    "    # items in the data_path directory and if they are directories, add them to \n",
    "    # the list\"\n",
    "    file_paths = []\n",
    "    patch_ids = [sub_dir for sub_dir in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, sub_dir))]\n",
    "    \n",
    "    for patch in patch_ids:\n",
    "        # get all subsamples of each patch\n",
    "        subsamples = os.listdir(os.path.join(data_path, patch, 'input'))\n",
    "        # add subsamples to file_path list\n",
    "        file_paths.extend(\n",
    "            (\n",
    "                os.path.join(data_path, patch, 'input', subsample),\n",
    "                os.path.join(data_path, patch, 'target', subsample)\n",
    "            ) for subsample in subsamples\n",
    "        )\n",
    "        \n",
    "    \n",
    "    # check to make sure files exist\n",
    "    for file_path in file_paths:\n",
    "        if not os.path.isfile(file_path[0]):\n",
    "            raise FileNotFoundError(f'Input file {file_path[0]} not found')\n",
    "        if not os.path.isfile(file_path[1]):\n",
    "            raise FileNotFoundError(f'Label file {file_path[1]} not found')\n",
    "    \n",
    "    return file_paths\n",
    "    \n",
    "    \n",
    "file_paths = get_list_of_files('./data')\n",
    "print(f'Found {len(file_paths)} files') # always a good idea to print out the number of files found\n",
    "print(file_paths[0]) # take a look at the first file path input/target 2-tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'rasterio' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n rasterio ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "src_file = './data/m_3607626_ne_18_1/input/00000.tif'\n",
    "with rasterio.open(src_file) as src:\n",
    "    meta = src.meta # grab geo metadata\n",
    "    data = src.read() # grab raster data (as numpy array)\n",
    "    red_band = src.read(1) # only grab red band (as numpy array)\n",
    "    \n",
    "print('raster metadata:', meta)\n",
    "print('raster shape:', data.shape)\n",
    "print('red band raster shape:', red_band.shape)\n",
    "\n",
    "rasterio.plot.show(data, transform=meta['transform'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Dataset class\n",
    "\n",
    "In order to load data to train a neural network model in PyTorch, we need to create a custom class that tells PyTorch *how* to load each sample into memory, and what transformations need to be performed on each sample. If you're unfamiliar with this practice, you may not immediately see the value in it compared to simply using a list of samples or `numpy` arrays. Indeed, it may seem like more unnecessary boiler-plate code, but there are several important reasons why creating a custom `Dataset` class has its advantages:\n",
    "\n",
    "1. It gives us near complete control on how data is loaded and passed to the model. For small, simple datasets it often more than enough to use a `numpy` array to load samples for training. However, when working with large, complicated datasets, we often need to load samples directly from the disk on the fly and modify them to be suitable for training. Using the `__getitem__` method, we can pass in an index and load \n",
    "\n",
    "2 - Using the `Dataset` class allows us to unlock some of the powerful features of object-oriented programming. We can store important information about the dataset - such as the distribution of classes, means, standard deviations, metadata, and more and access them easily, from both within the `Dataset` class definition and the object itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# our custom NAIP_Dataset class will inherit from the Dataset class\n",
    "class NAIP_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, files: list[tuple[str, str]], mode: str='train'):\n",
    "        self.file_path_list = files\n",
    "        self.mode = mode # defines whether we are in training or validation mode\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    # __getitem__() is called when indexed in the form dataset[i]\n",
    "    # typically a __getitem__() method returns a single sample from the dataset\n",
    "    # in the form of a tuple: (X, y) where X is the data fed into\n",
    "    # the model and y is the ground truch label associated with the data.\n",
    "    # In our case, we will return a tuple of the form (X, y, meta), whera meta\n",
    "    # is the metadata associated with the raster file.\n",
    "    def __getitem__(self, index) -> tuple[torch.Tensor, torch.Tensor, dict]:\n",
    "        \n",
    "        file_path = self.file_path_list[index]\n",
    "        \n",
    "        X = rasterio.open(file_path[0]).read()\n",
    "        y = rasterio.open(file_path[1]).read()\n",
    "        \n",
    "        # convert to torch tensors\n",
    "        X = torch.from_numpy(X)\n",
    "        y = torch.from_numpy(y)\n",
    "        \n",
    "        # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Image Transforms (Rotate and Flip)\n",
    "\n",
    "When training a deep learning model for image tasks, it is a good idea to use data augmentation in the form of image transforms during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rasterio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
